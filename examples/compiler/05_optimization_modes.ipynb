{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I - Devito Performance modes\n",
    "\n",
    "This tutorial illustrates the impact of several Devito optimization modes to the generated code.\n",
    "\n",
    "In Devito, an Operator has two preset optimization levels: `noop` and `advanced`.  With `noop`, no performance optimizations are introduced by the compiler. With `advanced`, several flop-reducing and data locality\n",
    "optimizations are applied. Examples of flop-reducing optimizations are common sub-expressions elimination and factorization; examples of data locality optimizations are loop fusion and cache blocking. SIMD vectorization is also applied through compiler auto-vectorization.\n",
    "\n",
    "To choose the performance optimization level we one shoud set the env variable DEVITO_OPT. By default it is set to the maximum level, `advanced`.\n",
    "\n",
    "e.g. `export DEVITO_OPT=advanced`\n",
    "\n",
    "alternaltively we can set the opt level at runtime using:\n",
    "\n",
    "`configuration['opt'] = advanced`\n",
    "\n",
    "or pass it directly to an `Operator` like:\n",
    "\n",
    "```\n",
    "eq = Eq(u.forward, u+2)\n",
    "op = Operator(eq, opt='noop')\n",
    "```\n",
    "\n",
    "We will use a xxx `Operator` that, at each time step, increments by 1 all points in the physical domain and the code produced in each case.\n",
    "\n",
    "\n",
    "We will incrementally apply several optimizations before reachint the advanced level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will be used to print the difference between the generated code.\n",
    "def _unidiff_output(expected, actual):\n",
    "    \"\"\"\n",
    "    Helper function. Returns a string containing the unified diff of two multiline strings.\n",
    "    \"\"\"\n",
    "    import difflib\n",
    "    expected=expected.splitlines(1)\n",
    "    actual=actual.splitlines(1)\n",
    "\n",
    "    diff=difflib.unified_diff(expected, actual)\n",
    "\n",
    "    return ''.join(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devito import clear_cache\n",
    "import numpy as np\n",
    "clear_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devito import Grid, TimeFunction, Eq, Operator, clear_cache\n",
    "from examples.cfd import plot_field, init_hat\n",
    "from devito import Eq, solve\n",
    "from devito import configuration\n",
    "\n",
    "# Initialise our problem parameters\n",
    "nx = 200\n",
    "ny = 200\n",
    "nz = 200\n",
    "\n",
    "grid = Grid(shape=(nx, ny, nz))\n",
    "u = TimeFunction(name='u', grid=grid, space_order=2)\n",
    "eq = Eq(u.forward, u.laplace + 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell illustrates the diff between an `Operator` that is not optimized at all, versus an `Operator` that is exploting OpenMP parallelism. We notice from the printed diff that the OpenMP code has:\n",
    "\n",
    " - a header `#include \"omp.h\"`\n",
    "as well as OpenMP directives:\n",
    " - `#pragma omp parallel num_threads(nthreads)`\n",
    " - `#pragma omp for collapse(1) schedule(static,1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- \n",
      "+++ \n",
      "@@ -2,6 +2,7 @@\n",
      " #include \"stdlib.h\"\n",
      " #include \"math.h\"\n",
      " #include \"sys/time.h\"\n",
      "+#include \"omp.h\"\n",
      " \n",
      " struct dataobj\n",
      " {\n",
      "@@ -20,7 +21,7 @@\n",
      " } ;\n",
      " \n",
      " \n",
      "-int Kernel(const float h_x, const float h_y, const float h_z, struct dataobj *restrict u_vec, const int time_M, const int time_m, struct profiler * timers, const int x_M, const int x_m, const int y_M, const int y_m, const int z_M, const int z_m)\n",
      "+int Kernel(const float h_x, const float h_y, const float h_z, struct dataobj *restrict u_vec, const int time_M, const int time_m, struct profiler * timers, const int x_M, const int x_m, const int y_M, const int y_m, const int z_M, const int z_m, const int nthreads)\n",
      " {\n",
      "   float (*restrict u)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]] __attribute__ ((aligned (64))) = (float (*)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]]) u_vec->data;\n",
      "   for (int time = time_m, t0 = (time)%(2), t1 = (time + 1)%(2); time <= time_M; time += 1, t0 = (time)%(2), t1 = (time + 1)%(2))\n",
      "@@ -28,13 +29,17 @@\n",
      "     struct timeval start_section0, end_section0;\n",
      "     gettimeofday(&start_section0, NULL);\n",
      "     /* Begin section0 */\n",
      "-    for (int x = x_m; x <= x_M; x += 1)\n",
      "+    #pragma omp parallel num_threads(nthreads)\n",
      "     {\n",
      "-      for (int y = y_m; y <= y_M; y += 1)\n",
      "+      #pragma omp for collapse(1) schedule(dynamic,1)\n",
      "+      for (int x = x_m; x <= x_M; x += 1)\n",
      "       {\n",
      "-        for (int z = z_m; z <= z_M; z += 1)\n",
      "+        for (int y = y_m; y <= y_M; y += 1)\n",
      "         {\n",
      "-          u[t1][x + 2][y + 2][z + 2] = 1.0e-1F + u[t0][x + 2][y + 2][z + 1]/pow(h_z, 2) - 2.0F*u[t0][x + 2][y + 2][z + 2]/pow(h_z, 2) + u[t0][x + 2][y + 2][z + 3]/pow(h_z, 2) + u[t0][x + 2][y + 1][z + 2]/pow(h_y, 2) - 2.0F*u[t0][x + 2][y + 2][z + 2]/pow(h_y, 2) + u[t0][x + 2][y + 3][z + 2]/pow(h_y, 2) + u[t0][x + 1][y + 2][z + 2]/pow(h_x, 2) - 2.0F*u[t0][x + 2][y + 2][z + 2]/pow(h_x, 2) + u[t0][x + 3][y + 2][z + 2]/pow(h_x, 2);\n",
      "+          for (int z = z_m; z <= z_M; z += 1)\n",
      "+          {\n",
      "+            u[t1][x + 2][y + 2][z + 2] = 1.0e-1F + u[t0][x + 2][y + 2][z + 1]/pow(h_z, 2) - 2.0F*u[t0][x + 2][y + 2][z + 2]/pow(h_z, 2) + u[t0][x + 2][y + 2][z + 3]/pow(h_z, 2) + u[t0][x + 2][y + 1][z + 2]/pow(h_y, 2) - 2.0F*u[t0][x + 2][y + 2][z + 2]/pow(h_y, 2) + u[t0][x + 2][y + 3][z + 2]/pow(h_y, 2) + u[t0][x + 1][y + 2][z + 2]/pow(h_x, 2) - 2.0F*u[t0][x + 2][y + 2][z + 2]/pow(h_x, 2) + u[t0][x + 3][y + 2][z + 2]/pow(h_x, 2);\n",
      "+          }\n",
      "         }\n",
      "       }\n",
      "     }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NBVAL_IGNORE_OUTPUT\n",
    "op_noop = Operator(eq, opt=('noop', {'openmp': False}))\n",
    "op_noop_openmp = Operator(eq, opt=('noop', {'openmp': True}))\n",
    "\n",
    "print(_unidiff_output(str(op_noop), str(op_noop_openmp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We showed the diff in the code by enabling OpenMP parallelism. Let's have a look at what happens when we enable some data-locality optimizations. The next cell prints the generated code when enabling cache blocking in addition to OpenMP parallelism. We notice the new `bf0` function where we iterate through blocks, still using OpenMP parallelism. The size of the blocks is by default decided form the autotuner unless explicitly defined by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#define _POSIX_C_SOURCE 200809L\n",
      "#include \"stdlib.h\"\n",
      "#include \"math.h\"\n",
      "#include \"sys/time.h\"\n",
      "#include \"omp.h\"\n",
      "\n",
      "struct dataobj\n",
      "{\n",
      "  void *restrict data;\n",
      "  int * size;\n",
      "  int * npsize;\n",
      "  int * dsize;\n",
      "  int * hsize;\n",
      "  int * hofs;\n",
      "  int * oofs;\n",
      "} ;\n",
      "\n",
      "struct profiler\n",
      "{\n",
      "  double section0;\n",
      "} ;\n",
      "\n",
      "void bf0(const float h_x, const float h_y, const float h_z, struct dataobj *restrict u_vec, const int t0, const int t1, const int x0_blk0_size, const int x_M, const int x_m, const int y0_blk0_size, const int y_M, const int y_m, const int z_M, const int z_m, const int nthreads);\n",
      "\n",
      "int Kernel(const float h_x, const float h_y, const float h_z, struct dataobj *restrict u_vec, const int time_M, const int time_m, struct profiler * timers, const int x0_blk0_size, const int x_M, const int x_m, const int y0_blk0_size, const int y_M, const int y_m, const int z_M, const int z_m, const int nthreads)\n",
      "{\n",
      "  for (int time = time_m, t0 = (time)%(2), t1 = (time + 1)%(2); time <= time_M; time += 1, t0 = (time)%(2), t1 = (time + 1)%(2))\n",
      "  {\n",
      "    struct timeval start_section0, end_section0;\n",
      "    gettimeofday(&start_section0, NULL);\n",
      "    /* Begin section0 */\n",
      "    bf0(h_x,h_y,h_z,u_vec,t0,t1,x0_blk0_size,x_M - (x_M - x_m + 1)%(x0_blk0_size),x_m,y0_blk0_size,y_M - (y_M - y_m + 1)%(y0_blk0_size),y_m,z_M,z_m,nthreads);\n",
      "    bf0(h_x,h_y,h_z,u_vec,t0,t1,x0_blk0_size,x_M - (x_M - x_m + 1)%(x0_blk0_size),x_m,(y_M - y_m + 1)%(y0_blk0_size),y_M,y_M - (y_M - y_m + 1)%(y0_blk0_size) + 1,z_M,z_m,nthreads);\n",
      "    bf0(h_x,h_y,h_z,u_vec,t0,t1,(x_M - x_m + 1)%(x0_blk0_size),x_M,x_M - (x_M - x_m + 1)%(x0_blk0_size) + 1,y0_blk0_size,y_M - (y_M - y_m + 1)%(y0_blk0_size),y_m,z_M,z_m,nthreads);\n",
      "    bf0(h_x,h_y,h_z,u_vec,t0,t1,(x_M - x_m + 1)%(x0_blk0_size),x_M,x_M - (x_M - x_m + 1)%(x0_blk0_size) + 1,(y_M - y_m + 1)%(y0_blk0_size),y_M,y_M - (y_M - y_m + 1)%(y0_blk0_size) + 1,z_M,z_m,nthreads);\n",
      "    /* End section0 */\n",
      "    gettimeofday(&end_section0, NULL);\n",
      "    timers->section0 += (double)(end_section0.tv_sec-start_section0.tv_sec)+(double)(end_section0.tv_usec-start_section0.tv_usec)/1000000;\n",
      "  }\n",
      "  return 0;\n",
      "}\n",
      "\n",
      "void bf0(const float h_x, const float h_y, const float h_z, struct dataobj *restrict u_vec, const int t0, const int t1, const int x0_blk0_size, const int x_M, const int x_m, const int y0_blk0_size, const int y_M, const int y_m, const int z_M, const int z_m, const int nthreads)\n",
      "{\n",
      "  float (*restrict u)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]] __attribute__ ((aligned (64))) = (float (*)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]]) u_vec->data;\n",
      "  if (x0_blk0_size == 0)\n",
      "  {\n",
      "    return;\n",
      "  }\n",
      "  #pragma omp parallel num_threads(nthreads)\n",
      "  {\n",
      "    #pragma omp for collapse(1) schedule(dynamic,1)\n",
      "    for (int x0_blk0 = x_m; x0_blk0 <= x_M; x0_blk0 += x0_blk0_size)\n",
      "    {\n",
      "      for (int y0_blk0 = y_m; y0_blk0 <= y_M; y0_blk0 += y0_blk0_size)\n",
      "      {\n",
      "        for (int x = x0_blk0; x <= x0_blk0 + x0_blk0_size - 1; x += 1)\n",
      "        {\n",
      "          for (int y = y0_blk0; y <= y0_blk0 + y0_blk0_size - 1; y += 1)\n",
      "          {\n",
      "            for (int z = z_m; z <= z_M; z += 1)\n",
      "            {\n",
      "              u[t1][x + 2][y + 2][z + 2] = 1.0e-1F + u[t0][x + 2][y + 2][z + 1]/pow(h_z, 2) - 2.0F*u[t0][x + 2][y + 2][z + 2]/pow(h_z, 2) + u[t0][x + 2][y + 2][z + 3]/pow(h_z, 2) + u[t0][x + 2][y + 1][z + 2]/pow(h_y, 2) - 2.0F*u[t0][x + 2][y + 2][z + 2]/pow(h_y, 2) + u[t0][x + 2][y + 3][z + 2]/pow(h_y, 2) + u[t0][x + 1][y + 2][z + 2]/pow(h_x, 2) - 2.0F*u[t0][x + 2][y + 2][z + 2]/pow(h_x, 2) + u[t0][x + 3][y + 2][z + 2]/pow(h_x, 2);\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NBVAL_IGNORE_OUTPUT\n",
    "op_blocking = Operator(eq, opt=('blocking', {'openmp': True}))\n",
    "print(op_blocking.ccode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually we avoid blocking the innermost loop in order to achieve better performance due to SIMD vectorization.\n",
    "However, if someone wants to, can enable innermost loop blocking as shown in the next cell: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_blocking_inner = Operator(eq, opt=('blocking', {'blockinner': True, 'openmp': True}))\n",
    "# print(op_blocking_inner.ccode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said before, we can also add SIMD vectorization to the generated code. We prefer that over innermost loop blocking. The next cell shows the addition of vectorization in the innermost `z loop` compared to plain blocking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- \n",
      "+++ \n",
      "@@ -58,6 +58,7 @@\n",
      "         {\n",
      "           for (int y = y0_blk0; y <= y0_blk0 + y0_blk0_size - 1; y += 1)\n",
      "           {\n",
      "+            #pragma omp simd aligned(u:32)\n",
      "             for (int z = z_m; z <= z_M; z += 1)\n",
      "             {\n",
      "               u[t1][x + 2][y + 2][z + 2] = 1.0e-1F + u[t0][x + 2][y + 2][z + 1]/pow(h_z, 2) - 2.0F*u[t0][x + 2][y + 2][z + 2]/pow(h_z, 2) + u[t0][x + 2][y + 2][z + 3]/pow(h_z, 2) + u[t0][x + 2][y + 1][z + 2]/pow(h_y, 2) - 2.0F*u[t0][x + 2][y + 2][z + 2]/pow(h_y, 2) + u[t0][x + 2][y + 3][z + 2]/pow(h_y, 2) + u[t0][x + 1][y + 2][z + 2]/pow(h_x, 2) - 2.0F*u[t0][x + 2][y + 2][z + 2]/pow(h_x, 2) + u[t0][x + 3][y + 2][z + 2]/pow(h_x, 2);\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NBVAL_IGNORE_OUTPUT\n",
    "op_blocking_simd = Operator(eq, opt=('blocking', 'simd', {'openmp': True}))\n",
    "print(_unidiff_output(str(op_blocking), str(op_blocking_simd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However Devito by default, can optimize even more the generated code. When Devito optimization level is set to\n",
    "`advanced` as stated in the introductory first cell. Let's have a look at the diff between the `advanced` optimization level version and a version with loop blocking and SIMD vectorization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- \n",
      "+++ \n",
      "@@ -2,6 +2,8 @@\n",
      " #include \"stdlib.h\"\n",
      " #include \"math.h\"\n",
      " #include \"sys/time.h\"\n",
      "+#include \"xmmintrin.h\"\n",
      "+#include \"pmmintrin.h\"\n",
      " #include \"omp.h\"\n",
      " \n",
      " struct dataobj\n",
      "@@ -24,6 +26,9 @@\n",
      " \n",
      " int Kernel(const float h_x, const float h_y, const float h_z, struct dataobj *restrict u_vec, const int time_M, const int time_m, struct profiler * timers, const int x0_blk0_size, const int x_M, const int x_m, const int y0_blk0_size, const int y_M, const int y_m, const int z_M, const int z_m, const int nthreads)\n",
      " {\n",
      "+  /* Flush denormal numbers to zero in hardware */\n",
      "+  _MM_SET_DENORMALS_ZERO_MODE(_MM_DENORMALS_ZERO_ON);\n",
      "+  _MM_SET_FLUSH_ZERO_MODE(_MM_FLUSH_ZERO_ON);\n",
      "   for (int time = time_m, t0 = (time)%(2), t1 = (time + 1)%(2); time <= time_M; time += 1, t0 = (time)%(2), t1 = (time + 1)%(2))\n",
      "   {\n",
      "     struct timeval start_section0, end_section0;\n",
      "@@ -61,7 +66,8 @@\n",
      "             #pragma omp simd aligned(u:32)\n",
      "             for (int z = z_m; z <= z_M; z += 1)\n",
      "             {\n",
      "-              u[t1][x + 2][y + 2][z + 2] = 1.0e-1F + u[t0][x + 2][y + 2][z + 1]/pow(h_z, 2) - 2.0F*u[t0][x + 2][y + 2][z + 2]/pow(h_z, 2) + u[t0][x + 2][y + 2][z + 3]/pow(h_z, 2) + u[t0][x + 2][y + 1][z + 2]/pow(h_y, 2) - 2.0F*u[t0][x + 2][y + 2][z + 2]/pow(h_y, 2) + u[t0][x + 2][y + 3][z + 2]/pow(h_y, 2) + u[t0][x + 1][y + 2][z + 2]/pow(h_x, 2) - 2.0F*u[t0][x + 2][y + 2][z + 2]/pow(h_x, 2) + u[t0][x + 3][y + 2][z + 2]/pow(h_x, 2);\n",
      "+              float r0 = -2.0F*u[t0][x + 2][y + 2][z + 2];\n",
      "+              u[t1][x + 2][y + 2][z + 2] = 1.0e-1F + (r0 + u[t0][x + 2][y + 2][z + 1] + u[t0][x + 2][y + 2][z + 3])/((h_z*h_z)) + (r0 + u[t0][x + 2][y + 1][z + 2] + u[t0][x + 2][y + 3][z + 2])/((h_y*h_y)) + (r0 + u[t0][x + 1][y + 2][z + 2] + u[t0][x + 3][y + 2][z + 2])/((h_x*h_x));\n",
      "             }\n",
      "           }\n",
      "         }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NBVAL_IGNORE_OUTPUT\n",
    "op_advanced = Operator(eq, opt=('advanced', {'openmp': True}))\n",
    "print(_unidiff_output(str(op_blocking_simd), str(op_advanced)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code diff in the cell above depicts some differences between these two modes.\n",
    "First of all, we notice the addition of \n",
    "```\n",
    "+#include \"xmmintrin.h\"\n",
    "+#include \"pmmintrin.h\"\n",
    "```\n",
    "and \n",
    "```\n",
    "+  /* Flush denormal numbers to zero in hardware */\n",
    "+  _MM_SET_DENORMALS_ZERO_MODE(_MM_DENORMALS_ZERO_ON);\n",
    "+  _MM_SET_FLUSH_ZERO_MODE(_MM_FLUSH_ZERO_ON);\n",
    "```\n",
    "Denormals are normally flushed when using SSE-based instruction sets, except when compiling shared objects.\n",
    "\n",
    "Then, at the PDE update we see that we get `float r0` out of the main update expression as it is a common expression that can we avoid computing again and again.\n",
    "\n",
    "This flop reduction after symbolic optimization results to an `Operator` that is cheaper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Operator `Kernel` generated in 0.12 s\n",
      "  * lowering.IET: 0.06 s (52.6 %)\n",
      "     * specializing.IET: 0.04 s (35.1 %)\n",
      "  * lowering.Clusters: 0.03 s (26.3 %)\n",
      "Flops reduction after symbolic optimization: [30 --> 30]\n",
      "Operator `Kernel` generated in 0.23 s\n",
      "  * lowering.IET: 0.13 s (58.2 %)\n",
      "     * specializing.IET: 0.11 s (49.3 %)\n",
      "        * optimize_halospots: 0.07 s (31.4 %)\n",
      "  * lowering.Clusters: 0.06 s (26.9 %)\n",
      "     * specializing.Clusters: 0.05 s (22.4 %)\n",
      "Flops reduction after symbolic optimization: [30 --> 19]\n"
     ]
    }
   ],
   "source": [
    "#NBVAL_IGNORE_OUTPUT\n",
    "configuration['log-level']='DEBUG'\n",
    "op_blocking_simd = Operator(eq, opt=('blocking', 'simd', {'openmp': True}))\n",
    "op_advanced = Operator(eq, opt=('advanced', {'openmp': True}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 30-flop expression\n",
    "\n",
    "`u[t1][x + 2][y + 2][z + 2] = 1.0e-1F + u[t0][x + 2][y + 2][z + 1]/pow(h_z, 2) - 2.0F*u[t0][x + 2][y + 2][z + 2]/pow(h_z, 2) + u[t0][x + 2][y + 2][z + 3]/pow(h_z, 2) + u[t0][x + 2][y + 1][z + 2]/pow(h_y, 2) - 2.0F*u[t0][x + 2][y + 2][z + 2]/pow(h_y, 2) + u[t0][x + 2][y + 3][z + 2]/pow(h_y, 2) + u[t0][x + 1][y + 2][z + 2]/pow(h_x, 2) - 2.0F*u[t0][x + 2][y + 2][z + 2]/pow(h_x, 2) + u[t0][x + 3][y + 2][z + 2]/pow(h_x, 2);`\n",
    "\n",
    "is now a 19-flop\n",
    "\n",
    "`\n",
    "float r0 = -2.0F*u[t0][x + 2][y + 2][z + 2];\n",
    "u[t1][x + 2][y + 2][z + 2] = 1.0e-1F + (r0 + u[t0][x + 2][y + 2][z + 1] + u[t0][x + 2][y + 2][z + 3])/((h_z*h_z)) + (r0 + u[t0][x + 2][y + 1][z + 2] + u[t0][x + 2][y + 3][z + 2])/((h_y*h_y)) + (r0 + u[t0][x + 1][y + 2][z + 2] + u[t0][x + 3][y + 2][z + 2])/((h_x*h_x));\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We suggest to always run with `opt='advanced'` (set by default) unless preferred otherwise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "459.85px",
    "left": "1723.22px",
    "right": "20px",
    "top": "120px",
    "width": "352.767px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
