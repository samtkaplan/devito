{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance optimization overview\n",
    "\n",
    "This tutorial illustrates the performance optimizations applied to the code generated by an `Operator`. As we shall see, most optimizations are automatically applied as they're known to systematically improve performance. Others, whose impact varies across different `Operator`s, are instead to be enabled through specific options.\n",
    "\n",
    "An Operator has several preset **optimization levels**; the fundamental ones are `noop` and `advanced`. With `noop`, no performance optimizations are introduced by the compiler. With `advanced`, several flop-reducing and data locality _optimization passes_ are performed. Examples of flop-reducing optimization passes are common sub-expressions elimination and factorization; examples of data locality optimization passes are loop fusion and cache blocking. SIMD vectorization, via compiler auto-vectorization, is enforced through OpenMP pragmas.\n",
    "\n",
    "An optimization pass may provide knobs, or **options**, for fine-grained tuning. As explained in the next sections, some of these options are given at compile-time, others at run-time.\n",
    "\n",
    "**\\*\\* Remark \\*\\***\n",
    "\n",
    "Parallelism -- both shared-memory (e.g., OpenMP) and distributed-memory (MPI) -- is _by default disabled_ and is _not_ controlled via the optimization level. In this tutorial we will also show how to enable OpenMP parallelism (you'll see it's trivial!). A mini-guide about parallelism in Devito and related aspects is also available [here](https://github.com/devitocodes/devito/tree/master/benchmarks/user#a-step-back-configuring-your-machine-for-reliable-benchmarking). \n",
    "\n",
    "**\\*\\*\\*\\***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API\n",
    "\n",
    "The optimization level may be changed in various ways:\n",
    "\n",
    "* globally, through the `DEVITO_OPT` environment variable. For example, to disable all optimizations on all `Operator`s, one should run with\n",
    "\n",
    "```\n",
    "DEVITO_OPT=noop python ...\n",
    "```\n",
    "\n",
    "* programmatically, adding the following lines to a program\n",
    "\n",
    "```\n",
    "from devito import configuration\n",
    "configuration['opt'] = 'noop'\n",
    "```\n",
    "\n",
    "* locally, as an `Operator` argument\n",
    "\n",
    "```\n",
    "Operator(..., opt='noop')\n",
    "```\n",
    "\n",
    "Local takes precedence over programmatic, and programmatic takes precedence over global.\n",
    "\n",
    "The optimization options, instead, may only be changed locally. The syntax to specify an option is\n",
    "\n",
    "```\n",
    "Operator(..., opt=('advanced', {<optimization options>})\n",
    "```\n",
    "\n",
    "A concrete example (you can ignore the meaning for now) is\n",
    "\n",
    "```\n",
    "Operator(..., opt=('advanced', {'blocklevels': 2})\n",
    "```\n",
    "\n",
    "That is, options are to be specified _together with_ the optimization level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default values\n",
    "\n",
    "By default, all `Operator`s are run with the optimization level set to `advanced` and with all options disabled. So this\n",
    "\n",
    "```\n",
    "Operator(Eq(...))\n",
    "```\n",
    "\n",
    "is equivalent to\n",
    "\n",
    "```\n",
    "Operator(Eq(...), opt='advanced')\n",
    "```\n",
    "\n",
    "and obviously also to\n",
    "\n",
    "```\n",
    "Operator(Eq(...), opt=('advanced', {}))\n",
    "```\n",
    "\n",
    "In virtually all scenarios, regardless of application and underlying architecture, this ensures very good performance -- but not necessarily the very best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities\n",
    "\n",
    "The following functions will be used throughout the notebook for various purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: George -- I guess we could (and should!) move this under examples/performance/utils.py ... \n",
    "def _unidiff_output(expected, actual):\n",
    "    \"\"\"\n",
    "    Helper function. Returns a string containing the unified diff of two multiline strings.\n",
    "    \"\"\"\n",
    "    import difflib\n",
    "    expected=expected.splitlines(1)\n",
    "    actual=actual.splitlines(1)\n",
    "\n",
    "    diff=difflib.unified_diff(expected, actual)\n",
    "\n",
    "    return ''.join(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running example\n",
    "\n",
    "Throughout the notebook we will generate `Operator`s for the following time-marching `Eq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import sin\n",
    "from devito import Eq, Grid, Operator, Function, TimeFunction\n",
    "\n",
    "grid = Grid(shape=(80, 80, 80))\n",
    "\n",
    "f = Function(name='f', grid=grid)\n",
    "u = TimeFunction(name='u', grid=grid, space_order=2)\n",
    "\n",
    "eq = Eq(u.forward, sin(f)*u.dy.dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite its simplicity, this `Eq` is all we need to showcase the key components of the Devito optimization engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenMP Parallelism\n",
    "\n",
    "There are several ways to enable OpenMP parallelism. The one we use here consists of supplying an **option** to an `Operator`. The next cell illustrates the difference between two `Operator`s generated with the `noop` optimization level, but with OpenMP enabled on the latter `Operator`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: we only need this cell for Continuous Integration, which runs with OpenMP enabled\n",
    "from devito import configuration\n",
    "configuration['language'] = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#define _POSIX_C_SOURCE 200809L\n",
      "#include \"stdlib.h\"\n",
      "#include \"math.h\"\n",
      "#include \"sys/time.h\"\n",
      "#include \"omp.h\"\n",
      "\n",
      "struct dataobj\n",
      "{\n",
      "  void *restrict data;\n",
      "  int * size;\n",
      "  int * npsize;\n",
      "  int * dsize;\n",
      "  int * hsize;\n",
      "  int * hofs;\n",
      "  int * oofs;\n",
      "} ;\n",
      "\n",
      "struct profiler\n",
      "{\n",
      "  double section0;\n",
      "} ;\n",
      "\n",
      "\n",
      "int Kernel(struct dataobj *restrict f_vec, const float h_y, struct dataobj *restrict u_vec, const int time_M, const int time_m, struct profiler * timers, const int x_M, const int x_m, const int y_M, const int y_m, const int z_M, const int z_m, const int nthreads)\n",
      "{\n",
      "  float (*restrict f)[f_vec->size[1]][f_vec->size[2]] __attribute__ ((aligned (64))) = (float (*)[f_vec->size[1]][f_vec->size[2]]) f_vec->data;\n",
      "  float (*restrict u)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]] __attribute__ ((aligned (64))) = (float (*)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]]) u_vec->data;\n",
      "\n",
      "  for (int time = time_m, t0 = (time)%(2), t1 = (time + 1)%(2); time <= time_M; time += 1, t0 = (time)%(2), t1 = (time + 1)%(2))\n",
      "  {\n",
      "    struct timeval start_section0, end_section0;\n",
      "    gettimeofday(&start_section0, NULL);\n",
      "    /* Begin section0 */\n",
      "    #pragma omp parallel num_threads(nthreads)\n",
      "    {\n",
      "      #pragma omp for collapse(1) schedule(dynamic,1)\n",
      "      for (int x = x_m; x <= x_M; x += 1)\n",
      "      {\n",
      "        for (int y = y_m; y <= y_M; y += 1)\n",
      "        {\n",
      "          for (int z = z_m; z <= z_M; z += 1)\n",
      "          {\n",
      "            u[t1][x + 2][y + 2][z + 2] = (-(-u[t0][x + 2][y + 2][z + 2]/h_y + u[t0][x + 2][y + 3][z + 2]/h_y)/h_y + (-u[t0][x + 2][y + 3][z + 2]/h_y + u[t0][x + 2][y + 4][z + 2]/h_y)/h_y)*sin(f[x + 1][y + 1][z + 1]);\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    /* End section0 */\n",
      "    gettimeofday(&end_section0, NULL);\n",
      "    timers->section0 += (double)(end_section0.tv_sec-start_section0.tv_sec)+(double)(end_section0.tv_usec-start_section0.tv_usec)/1000000;\n",
      "  }\n",
      "  return 0;\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "op0 = Operator(eq, opt=('noop'))\n",
    "op0_omp = Operator(eq, opt=('noop', {'openmp': True}))\n",
    "\n",
    "# print(op0)\n",
    "# print(_unidiff_output(str(op0), str(op0_omp)))  # Uncomment to print out the diff only\n",
    "print(op0_omp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OpenMP-ized `op0_omp` `Operator`:\n",
    "\n",
    " - includes the necessary header file `#include \"omp.h\"`\n",
    " - the `#pragma omp parallel num_threads(nthreads)` directive\n",
    " - the `#pragma omp for collapse(...) schedule(dynamic,1)` directive\n",
    " \n",
    "More complex `Operator`s will have more directives, more types of directives, different iteration scheduling strategies based on heuristics and empirical tuning (e.g., `static` instead of `dynamic`), etc.\n",
    "\n",
    "We note how the OpenMP optimization pass also introduces a new symbol, `nthreads`. This allows users to explicitly control the number of threads with which an `Operator` is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op0_omp.apply(time_M=0)  # Picks up `nthreads` from the standard environment variable OMP_NUM_THREADS\n",
    "op0_omp.apply(time_M=0, nthreads=2)  # Runs with 2 threads per parallel loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `advanced` mode\n",
    "\n",
    "As already explained, `advanced` is the default optimization level in Devito. This mode performs several compilation passes to optimize the `Operator` for computation (number of flops), working set size, and data locality.\n",
    "\n",
    "In the next paragraphs we dissect the `advanced` mode and analyze, one by one, some of its key passes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop blocking\n",
    "\n",
    "The next cell creates a new `Operator` that adds loop blocking to what we had in `op0_omp`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op1_omp = Operator(eq, opt=('blocking', {'openmp': True}))\n",
    "print(op1_omp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\\*\\* Remark \\*\\***\n",
    "\n",
    "`'blocking'` is **not** an optimization level -- it rather identifies a very specific compilation pass. In other words, the `advanced` mode represents a set of passes, and `blocking` is one such pass.\n",
    "\n",
    "**\\*\\*\\*\\***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `blocking` pass creates additional loops over blocks. In this simple `Operator` there is just one loop nest, so only a pair of additional loops are created. In more complex `Operator`s, several loop nests may individually be blocked, whereas others may be left unblocked -- this is decided by the Devito compiler according to certain heuristics. The size of a block is represented by the symbols `x0_blk0_size` and `y0_blk0_size`, which are runtime parameters akin to `nthreads`. \n",
    "\n",
    "By default, Devito applies 2D blocking and sets the default block shape to 8x8. There are two ways to set a different block shape:\n",
    "\n",
    "* passing an explicit value. In the example below we would run with a 24x8 block shape\n",
    "\n",
    "```\n",
    "op1_omp.apply(..., x0_blk0_size=24)\n",
    "```\n",
    "\n",
    "* letting the autotuner run for a while, looking for a better block shape. There are several autotuning modes. A short summary is available [here](https://github.com/devitocodes/devito/wiki/FAQ#devito_autotuning)\n",
    "\n",
    "```\n",
    "op1_omp.apply(..., autotune='aggressive')\n",
    "```\n",
    "\n",
    "Loop blocking also provides two optimization options:\n",
    "\n",
    "* `blockinner={False, True}` -- to enable 3D (or any nD, n>2) blocking\n",
    "* `blocklevels={int}` -- to enable hierarchical blocking, to exploit the cache hierarchy \n",
    "\n",
    "In the example below, we construct an `Operator` featuring six-dimensional loop blocking, where the first three loops represent outer blocks, whereas the second three loops represent inner blocks within an outer block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op1_omp_6D = Operator(eq, opt=('blocking', {'blockinner': True, 'blocklevels': 2, 'openmp': True}))\n",
    "print(op1_omp_6D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIMD vectorization\n",
    "\n",
    "Devito enforces SIMD vectorization through OpenMP pragmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op2_omp = Operator(eq, opt=('blocking', 'simd', {'openmp': True}))\n",
    "# print(op2_omp)  # Uncomment to see the generated code\n",
    "# print(_unidiff_output(str(op1_omp), str(op2_omp)))  # Uncomment to print out the diff only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code motion\n",
    "\n",
    "The `advanced` mode performs a code motion pass. In explicit PDE solvers, this is most commonly used to lift expensive time-invariant sub-expressions out of the inner loops. The pass is however quite general in that it is not restricted to the concept of time-invariance -- any sub-expression invariant with respect to a subset of `Dimension`s is a code motion candidate. In the example below, we see that `sin(f)` gets hoisted out of the inner loops since it is determined to be an expensive invariant sub-expression. In other words, the compiler trades the redundant computation of `sin(f)` for additional storage (the `r1[...]` array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#define _POSIX_C_SOURCE 200809L\n",
      "#include \"stdlib.h\"\n",
      "#include \"math.h\"\n",
      "#include \"sys/time.h\"\n",
      "#include \"omp.h\"\n",
      "\n",
      "struct dataobj\n",
      "{\n",
      "  void *restrict data;\n",
      "  int * size;\n",
      "  int * npsize;\n",
      "  int * dsize;\n",
      "  int * hsize;\n",
      "  int * hofs;\n",
      "  int * oofs;\n",
      "} ;\n",
      "\n",
      "struct profiler\n",
      "{\n",
      "  double section0;\n",
      "  double section1;\n",
      "} ;\n",
      "\n",
      "\n",
      "int Kernel(struct dataobj *restrict f_vec, const float h_y, struct dataobj *restrict u_vec, const int x_size, const int y_size, const int z_size, const int time_M, const int time_m, struct profiler * timers, const int x_M, const int x_m, const int y_M, const int y_m, const int z_M, const int z_m, const int nthreads)\n",
      "{\n",
      "  float (*restrict f)[f_vec->size[1]][f_vec->size[2]] __attribute__ ((aligned (64))) = (float (*)[f_vec->size[1]][f_vec->size[2]]) f_vec->data;\n",
      "  float (*restrict u)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]] __attribute__ ((aligned (64))) = (float (*)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]]) u_vec->data;\n",
      "\n",
      "  float (*r1)[y_size][z_size];\n",
      "  posix_memalign((void**)&r1, 64, sizeof(float[x_size][y_size][z_size]));\n",
      "\n",
      "  struct timeval start_section0, end_section0;\n",
      "  gettimeofday(&start_section0, NULL);\n",
      "  /* Begin section0 */\n",
      "  #pragma omp parallel num_threads(nthreads)\n",
      "  {\n",
      "    #pragma omp for collapse(1) schedule(static,1)\n",
      "    for (int x = x_m; x <= x_M; x += 1)\n",
      "    {\n",
      "      for (int y = y_m; y <= y_M; y += 1)\n",
      "      {\n",
      "        for (int z = z_m; z <= z_M; z += 1)\n",
      "        {\n",
      "          r1[x][y][z] = sin(f[x + 1][y + 1][z + 1]);\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  /* End section0 */\n",
      "  gettimeofday(&end_section0, NULL);\n",
      "  timers->section0 += (double)(end_section0.tv_sec-start_section0.tv_sec)+(double)(end_section0.tv_usec-start_section0.tv_usec)/1000000;\n",
      "  for (int time = time_m, t0 = (time)%(2), t1 = (time + 1)%(2); time <= time_M; time += 1, t0 = (time)%(2), t1 = (time + 1)%(2))\n",
      "  {\n",
      "    struct timeval start_section1, end_section1;\n",
      "    gettimeofday(&start_section1, NULL);\n",
      "    /* Begin section1 */\n",
      "    #pragma omp parallel num_threads(nthreads)\n",
      "    {\n",
      "      #pragma omp for collapse(1) schedule(dynamic,1)\n",
      "      for (int x = x_m; x <= x_M; x += 1)\n",
      "      {\n",
      "        for (int y = y_m; y <= y_M; y += 1)\n",
      "        {\n",
      "          for (int z = z_m; z <= z_M; z += 1)\n",
      "          {\n",
      "            u[t1][x + 2][y + 2][z + 2] = (-(-u[t0][x + 2][y + 2][z + 2]/h_y + u[t0][x + 2][y + 3][z + 2]/h_y)/h_y + (-u[t0][x + 2][y + 3][z + 2]/h_y + u[t0][x + 2][y + 4][z + 2]/h_y)/h_y)*r1[x][y][z];\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    /* End section1 */\n",
      "    gettimeofday(&end_section1, NULL);\n",
      "    timers->section1 += (double)(end_section1.tv_sec-start_section1.tv_sec)+(double)(end_section1.tv_usec-start_section1.tv_usec)/1000000;\n",
      "  }\n",
      "\n",
      "  free(r1);\n",
      "  return 0;\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "op3_omp = Operator(eq, opt=('lift', {'openmp': True}))\n",
    "print(op3_omp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple flop-reducing transformations\n",
    "\n",
    "Among the simpler flop-reducing transformations applied by the `advanved` mode we find:\n",
    "\n",
    "* \"classic\" common sub-expressions elimination (CSE),\n",
    "* factorization,\n",
    "* optimization of powers\n",
    "\n",
    "The cell below shows how the computation of `u` changes by incrementally applying these three passes. First of all, we observe how the symbolic spacing `h_y` gets assigned to a temporary, `r0`, due to appearing in several sub-expressions. This is the effect of CSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- \n",
      "+++ \n",
      "@@ -40,7 +40,8 @@\n",
      "         {\n",
      "           for (int z = z_m; z <= z_M; z += 1)\n",
      "           {\n",
      "-            u[t1][x + 2][y + 2][z + 2] = (-(-u[t0][x + 2][y + 2][z + 2]/h_y + u[t0][x + 2][y + 3][z + 2]/h_y)/h_y + (-u[t0][x + 2][y + 3][z + 2]/h_y + u[t0][x + 2][y + 4][z + 2]/h_y)/h_y)*sin(f[x + 1][y + 1][z + 1]);\n",
      "+            float r0 = 1.0/h_y;\n",
      "+            u[t1][x + 2][y + 2][z + 2] = (-r0*(-r0*u[t0][x + 2][y + 2][z + 2] + r0*u[t0][x + 2][y + 3][z + 2]) + r0*(-r0*u[t0][x + 2][y + 3][z + 2] + r0*u[t0][x + 2][y + 4][z + 2]))*sin(f[x + 1][y + 1][z + 1]);\n",
      "           }\n",
      "         }\n",
      "       }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "op4_omp = Operator(eq, opt=('cse', {'openmp': True}))\n",
    "print(_unidiff_output(str(op0_omp), str(op4_omp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factorization causes the collection of `r0` in two different sub-expressions. In larger, more complex examples, the impact of factorization is typically much more pronounced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- \n",
      "+++ \n",
      "@@ -41,7 +41,7 @@\n",
      "           for (int z = z_m; z <= z_M; z += 1)\n",
      "           {\n",
      "             float r0 = 1.0/h_y;\n",
      "-            u[t1][x + 2][y + 2][z + 2] = (r0*(-r0*(-u[t0][x + 2][y + 2][z + 2]) - r0*u[t0][x + 2][y + 3][z + 2]) + r0*(r0*(-u[t0][x + 2][y + 3][z + 2]) + r0*u[t0][x + 2][y + 4][z + 2]))*sin(f[x + 1][y + 1][z + 1]);\n",
      "+            u[t1][x + 2][y + 2][z + 2] = (-r0*(-r0*u[t0][x + 2][y + 2][z + 2] + r0*u[t0][x + 2][y + 3][z + 2]) + r0*(-r0*u[t0][x + 2][y + 3][z + 2] + r0*u[t0][x + 2][y + 4][z + 2]))*sin(f[x + 1][y + 1][z + 1]);\n",
      "           }\n",
      "         }\n",
      "       }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "op5_omp = Operator(eq, opt=('cse', 'factorize', {'openmp': True}))\n",
    "print(_unidiff_output(str(op5_omp), str(op4_omp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no powers in this example, so the `opt-pows` pass has no effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "op6_omp = Operator(eq, opt=('cse', 'factorize', 'opt-pows', {'openmp': True}))\n",
    "print(_unidiff_output(str(op6_omp), str(op5_omp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-iteration redundancy elimination (CIRE)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All optimizations together\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = Operator(eq, openmp=True)  # `openmp=True` shortcut for `opt=('advanced', {'openmp': True})`\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other things that the `advanced` mode does which are not described in this introductory tutorial. Some are visible printing `op` (e.g., the addition of denormal-numbers related macros), others are not (e.g., all of the MPI-related optimizations). This will be covered in another tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- Michael E. Wolf and Monica S. Lam. 1991. A data locality optimizing algorithm. In Proceedings of the ACM SIGPLAN 1991 conference on Programming language design and implementation (PLDI ’91). Association for Computing Machinery, New York, NY, USA, 30–44. DOI:https://doi.org/10.1145/113445.113449"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "459.85px",
    "left": "1723.22px",
    "right": "20px",
    "top": "120px",
    "width": "352.767px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
